{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# IPython candies...\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim, tensor, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "feb13fc88688cd77d0f4266f0d95f6b5e341bfa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x225395cdf50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "b6e71245b5e82a99ce01f914e6efc37e5dd771b0"
   },
   "outputs": [],
   "source": [
    "try: # Use the default NLTK tokenizer.\n",
    "    from nltk import word_tokenize, sent_tokenize \n",
    "    # Testing whether it works. \n",
    "    # Sometimes it doesn't work on some machines because of setup issues.\n",
    "    word_tokenize(sent_tokenize(\"This is a foobar sentence. Yes it is.\")[0])\n",
    "except: # Use a naive sentence tokenizer and toktok.\n",
    "    import re\n",
    "    from nltk.tokenize import ToktokTokenizer\n",
    "    # See https://stackoverflow.com/a/25736515/610569\n",
    "    sent_tokenize = lambda x: re.split(r'(?<=[^A-Z].[.?]) +(?=[A-Z])', x)\n",
    "    # Use the toktok tokenizer that requires no dependencies.\n",
    "    toktok = ToktokTokenizer()\n",
    "    word_tokenize = word_tokenize = toktok.tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "e66bf66fae3734f95241eebc5ac8d11e61718bfe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import io #codecs\n",
    "\n",
    "\n",
    "# Text version of https://kilgarriff.co.uk/Publications/2005-K-lineer.pdf\n",
    "if os.path.isfile('1000sms.txt'):\n",
    "    with io.open('1000sms.txt'\n",
    "                 #, encoding='utf8'\n",
    "                ) as fin:\n",
    "        text = fin.read()\n",
    "else:\n",
    "    url = \"https://gist.githubusercontent.com/alvations/53b01e4076573fea47c6057120bb017a/raw/b01ff96a5f76848450e648f35da6497ca9454e4a/language-never-random.txt\"\n",
    "    text = requests.get(url).content.decode('utf8')\n",
    "    with io.open('language-never-random.txt', 'w', encoding='utf8') as fout:\n",
    "        fout.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "10e3d0a9d7d39774d41e60326ecf82f939dedcf6"
   },
   "outputs": [],
   "source": [
    "# Tokenize the text.\n",
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d971921fc3975505d0db84eca326744fb98c1ced"
   },
   "outputs": [],
   "source": [
    "class KilgariffDataset(nn.Module):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "        \n",
    "        # Initialize the vocab \n",
    "        special_tokens = {'<pad>': 0, '<unk>':1, '<s>':2, '</s>':3}\n",
    "        self.vocab = Dictionary(texts)\n",
    "        self.vocab.patch_with_special_tokens(special_tokens)\n",
    "        \n",
    "        # Keep track of the vocab size.\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        \n",
    "        # Keep track of how many data points.\n",
    "        self._len = len(texts)\n",
    "        \n",
    "        # Find the longest text in the data.\n",
    "        self.max_len = max(len(txt) for txt in texts) \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        vectorized_sent = self.vectorize(self.texts[index])\n",
    "        x_len = len(vectorized_sent)\n",
    "        # To pad the sentence:\n",
    "        # Pad left = 0; Pad right = max_len - len of sent.\n",
    "        pad_dim = (0, self.max_len - len(vectorized_sent))\n",
    "        vectorized_sent = F.pad(vectorized_sent, pad_dim, 'constant')\n",
    "        return {'x':vectorized_sent[:-1], \n",
    "                'y':vectorized_sent[1:], \n",
    "                'x_len':x_len}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def vectorize(self, tokens, start_idx=2, end_idx=3):\n",
    "        \"\"\"\n",
    "        :param tokens: Tokens that should be vectorized. \n",
    "        :type tokens: list(str)\n",
    "        \"\"\"\n",
    "        # See https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx \n",
    "        # Lets just cast list of indices into torch tensors directly =)\n",
    "        \n",
    "        vectorized_sent = [start_idx] + self.vocab.doc2idx(tokens) + [end_idx]\n",
    "        return torch.tensor(vectorized_sent)\n",
    "    \n",
    "    def unvectorize(self, indices):\n",
    "        \"\"\"\n",
    "        :param indices: Converts the indices back to tokens.\n",
    "        :type tokens: list(int)\n",
    "        \"\"\"\n",
    "        return [self.vocab[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4e39ea3edc9855cbc71e0b4e8c18dd1ca84e827f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1572"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kilgariff_data = KilgariffDataset(tokenized_text)\n",
    "len(kilgariff_data.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "149f189249edf73258f9456e86c2116cc2da3150"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': tensor([[  2,  73, 160,  ...,   0,   0,   0],\n",
      "        [  2, 213, 548,  ...,   0,   0,   0],\n",
      "        [  2, 183, 353,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [  2, 145, 675,  ...,   0,   0,   0],\n",
      "        [  2, 160,  23,  ...,   0,   0,   0],\n",
      "        [  2, 160, 353,  ...,   0,   0,   0]]), 'y': tensor([[ 73, 160, 674,  ...,   0,   0,   0],\n",
      "        [213, 548, 153,  ...,   0,   0,   0],\n",
      "        [183, 353, 286,  ...,   0,   0,   0],\n",
      "        ...,\n",
      "        [145, 675, 782,  ...,   0,   0,   0],\n",
      "        [160,  23, 179,  ...,   0,   0,   0],\n",
      "        [160, 353, 619,  ...,   0,   0,   0]]), 'x_len': tensor([20, 20, 14,  9,  9,  8,  8,  6,  6,  6])}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "dataloader = DataLoader(dataset=kilgariff_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for data_dict in dataloader:\n",
    "    # Sort indices of data in batch by lengths.\n",
    "    sorted_indices = np.array(data_dict['x_len']).argsort()[::-1].tolist()\n",
    "    data_batch = {name:_tensor[sorted_indices]\n",
    "                  for name, _tensor in data_dict.items()}\n",
    "    print(data_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "5aa5c2bd3bd13d6870441dec284d7762d6b8f1bd"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size, num_layers):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # Initialize the embedding layer with the \n",
    "        # - size of input (i.e. no. of words in input vocab)\n",
    "        # - no. of hidden nodes in the embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
    "        \n",
    "        # Initialize the GRU with the \n",
    "        # - size of the input (i.e. embedding layer)\n",
    "        # - size of the hidden layer \n",
    "        self.gru = nn.GRU(embedding_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Initialize the \"classifier\" layer to map the RNN outputs\n",
    "        # to the vocabulary. Remember we need to -1 because the \n",
    "        # vectorized sentence we left out one token for both x and y:\n",
    "        # - size of hidden_size of the GRU output.\n",
    "        # - size of vocabulary\n",
    "        self.classifier = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs, use_softmax=False, hidden=None):\n",
    "        # Look up for the embeddings for the input word indices.\n",
    "        embedded = self.embedding(inputs)\n",
    "        # Put the embedded inputs into the GRU.\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        \n",
    "        # Matrix manipulation magic.\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        # Technically, linear layer takes a 2-D matrix as input, so more manipulation...\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)\n",
    "        # Apply dropout.\n",
    "        output = F.dropout(output, 0.5)\n",
    "        # Put it through the classifier\n",
    "        # And reshape it to [batch_size x sequence_len x vocab_size]\n",
    "        output = self.classifier(output).view(batch_size, sequence_len, -1)\n",
    "        \n",
    "        return (F.softmax(output,dim=2), hidden) if use_softmax else (output, hidden)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "dce2418b4cede1f5dd3f104179fa69defaeceac3"
   },
   "outputs": [],
   "source": [
    "# Set the hidden_size of the GRU \n",
    "embed_size = 12\n",
    "hidden_size = 10\n",
    "num_layers = 1\n",
    "\n",
    "_encoder = Generator(len(kilgariff_data.vocab), embed_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0d24dcec5ce293c82663ecf9ce07528d1f125882"
   },
   "outputs": [],
   "source": [
    "# Take a batch.\n",
    "batch_size = 15\n",
    "dataloader = DataLoader(dataset=kilgariff_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "_batch = next(iter(dataloader))\n",
    "_inputs, _lengths = _batch['x'], _batch['x_len']\n",
    "_targets = _batch['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "009c1cc8d9f7517187bd9259473703baf5cbd349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output sizes:\t torch.Size([15, 227, 1572])\n",
      "Input sizes:\t 15 227 1572\n",
      "Target sizes:\t torch.Size([15, 227])\n"
     ]
    }
   ],
   "source": [
    "_output, _hidden = _encoder(_inputs)\n",
    "print('Output sizes:\\t', _output.shape)\n",
    "print('Input sizes:\\t', batch_size, kilgariff_data.max_len -1, len(kilgariff_data.vocab))\n",
    "print('Target sizes:\\t', _targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "b5ddd1dfa0736a64152d1b3acbedb118606d4a38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 227, 1572])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "ee773d9ff037f57b0ba49a0594f5ffb546da3498"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([227, 1572])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_output[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "07a81647f4724bc89e31eb0aaca301839d23b9fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 1572])\n"
     ]
    }
   ],
   "source": [
    "_, predicted_indices = torch.max(_output, dim=1)\n",
    "print(predicted_indices.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "cc11b8af72aa329ceb43d3b9e40d96efea23cb84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams(embed_size=250, hidden_size=250, num_layers=1, loss_func=<class 'torch.nn.modules.loss.CrossEntropyLoss'>, learning_rate=0.03, optimizer=<class 'torch.optim.adam.Adam'>, batch_size=245)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "_hyper = ['embed_size', 'hidden_size', 'num_layers',\n",
    "          'loss_func', 'learning_rate', 'optimizer', 'batch_size']\n",
    "Hyperparams = namedtuple('Hyperparams', _hyper)\n",
    "\n",
    "\n",
    "hyperparams = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
    "                          loss_func=nn.CrossEntropyLoss,\n",
    "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=245)\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "2654e746605c6480d1cc4cc1cf8b6c59fa3eefa4"
   },
   "outputs": [],
   "source": [
    "# Training routine.\n",
    "def train(num_epochs, dataloader, model, criterion, optimizer):\n",
    "    losses = []\n",
    "    plt.ion()\n",
    "    for _e in range(num_epochs):\n",
    "        for batch in tqdm(dataloader):\n",
    "            # Zero gradient.\n",
    "            optimizer.zero_grad()\n",
    "            x = batch['x'].to(device)\n",
    "            x_len = batch['x_len'].to(device)\n",
    "            y = batch['y'].to(device)\n",
    "            # Feed forward. \n",
    "            output, hidden = model(x, use_softmax=False)\n",
    "            # Compute loss:\n",
    "            # Shape of the `output` is [batch_size x sequence_len x vocab_size]\n",
    "            # Shape of `y` is [batch_size x sequence_len]\n",
    "            # CrossEntropyLoss expects `output` to be [batch_size x vocab_size x sequence_len]\n",
    "            _, prediction = torch.max(output, dim=2)\n",
    "            loss = criterion(output.permute(0, 2, 1), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.float().data)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(losses)\n",
    "        plt.pause(0.05)\n",
    "\n",
    "\n",
    "def initialize_data_model_optim_loss(hyperparams):\n",
    "    # Initialize the dataset and dataloader.\n",
    "    kilgariff_data = KilgariffDataset(tokenized_text)\n",
    "    dataloader = DataLoader(dataset=kilgariff_data, \n",
    "                            batch_size=hyperparams.batch_size, \n",
    "                            shuffle=True)\n",
    "\n",
    "    # Loss function.\n",
    "    criterion = hyperparams.loss_func(ignore_index=kilgariff_data.vocab.token2id['<pad>'], \n",
    "                                      reduction='mean')\n",
    "\n",
    "    # Model.\n",
    "    model = Generator(len(kilgariff_data.vocab), hyperparams.embed_size, \n",
    "                      hyperparams.hidden_size, hyperparams.num_layers).to(device)\n",
    "\n",
    "    # Optimizer.\n",
    "    optimizer = hyperparams.optimizer(model.parameters(), lr=hyperparams.learning_rate)\n",
    "    \n",
    "    return dataloader, model, optimizer, criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "5a5b3b2c17ba23fbb976f4a634ddd21e80e26c91"
   },
   "outputs": [],
   "source": [
    "def generate_example(model, temperature=1.0, max_len=100, hidden_state=None):\n",
    "    start_token, start_idx = '<s>', 2\n",
    "    # Start state.\n",
    "    inputs = torch.tensor(kilgariff_data.vocab.token2id[start_token]).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    sentence = [start_token]\n",
    "    i = 0\n",
    "    while i < max_len and sentence[-1] not in ['</s>', '<pad>']:\n",
    "        i += 1\n",
    "        \n",
    "        embedded = model.embedding(inputs)\n",
    "        output, hidden_state = model.gru(embedded, hidden_state)\n",
    "\n",
    "        batch_size, sequence_len, hidden_size = output.shape\n",
    "        output = output.contiguous().view(batch_size * sequence_len, hidden_size)    \n",
    "        output = model.classifier(output).view(batch_size, sequence_len, -1).squeeze(0)\n",
    "        #_, prediction = torch.max(F.softmax(output, dim=2), dim=2)\n",
    "        \n",
    "        word_weights = output.div(temperature).exp().cpu()\n",
    "        if len(word_weights.shape) > 1:\n",
    "            word_weights = word_weights[-1] # Pick the last word.    \n",
    "        word_idx = torch.multinomial(word_weights, 1).view(-1)\n",
    "        \n",
    "        sentence.append(kilgariff_data.vocab[int(word_idx)])\n",
    "        \n",
    "        inputs = tensor([kilgariff_data.vocab.token2id[word] for word in sentence]).unsqueeze(0).to(device)\n",
    "    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "de7efc9371e23d8ec2c73d647fdfc06a2805a573"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|██████████▍                                                                        | 2/16 [00:09<01:06,  4.73s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-fc50a3181a95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitialize_data_model_optim_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-ef6a2b1ae097>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(num_epochs, dataloader, model, criterion, optimizer)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m# Feed forward.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_softmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[1;31m# Compute loss:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;31m# Shape of the `output` is [batch_size x sequence_len x vocab_size]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-75d052b49fab>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, use_softmax, hidden)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0membedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Put the embedded inputs into the GRU.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Matrix manipulation magic.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 716\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
    "                          loss_func=nn.CrossEntropyLoss,\n",
    "                          learning_rate=0.03, optimizer=optim.Adam, batch_size=250)\n",
    "\n",
    "dataloader, model, optimizer, criterion = initialize_data_model_optim_loss(hyperparams)\n",
    "\n",
    "train(100, dataloader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "67548caaf4b02520b3eefcc87e5b7550ceff3e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> i meet where u park ur car ? </s>\n",
      "<s> can we confirm 4 me watching tv lor . </s>\n",
      "<s> u so gd lor . </s>\n",
      "<s> i call u 2 finish ur lect . </s>\n",
      "<s> ok i go change also then can call me ... ok lar i double check wif da glass exhibition ... i tot ü can go a bit bored ... hee ... ok ... depends on where we wan 2 go n get tickets ? </s>\n",
      "<s> how come u still want to come ? </s>\n",
      "<s> is ur paper tmr ? </s>\n",
      "<s> quite ex ... ok lor actually we take a nap first . </s>\n",
      "<s> ok ... u also forgot 2 check liao ... y u finish all ur dreams and call n i fetch us ... haha ... u takin linear algebra today ? </s>\n",
      "<s> re rite ... u know me well ? </s>\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    generate_example(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "8f2b7153dbe720c1fccbcbf5f8512a2bcce47689"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "torch.save(model.state_dict(), 'gru-model-1000sms.pth')\n",
    "\n",
    "hyperparams_str = Hyperparams(embed_size=250, hidden_size=250, num_layers=1,\n",
    "                          loss_func='nn.CrossEntropyLoss',\n",
    "                          learning_rate=0.03, optimizer='optim.Adam', batch_size=250)\n",
    "\n",
    "with open('gru-model-1000sms.json', 'w') as fout:\n",
    "    json.dump(dict(hyperparams_str._asdict()), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "fab8a4a413865aec5d69910460576fcf450896e2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "a3abe01633539dba8750208c84caecf40ca0a463"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
